{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9643cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"F:\\PML\\Datasets\")\n",
    "from sklearn.linear_model import LinearRegression, Ridge , Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a791ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast', 'Fly', 'Water', 'Superplasticizer', 'Coarse', 'Fine',\n",
       "       'Age', 'Strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv(r\"F:\\PML\\Cases\\Concrete_Strength\\Concrete_Data.csv\")\n",
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ae73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing.drop('Strength', axis=1)\n",
    "y = housing['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8982680",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                   random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec65439f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.6664343522079506,\n",
       " array([ 0.11499772,  0.10140332,  0.08255115, -0.17600505,  0.27810608,\n",
       "         0.01264227,  0.01537017,  0.11424624]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d505417e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6312960386440598\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = lr.predict(X_test)\n",
    "print(r2_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f777995f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "#ridge.intercept_, ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbcddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6312959887187692\n"
     ]
    }
   ],
   "source": [
    "y_pred_rg = ridge.predict(X_test)\n",
    "print(r2_score(y_test, y_pred_rg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee2abea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6312960381450502\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.01)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_rg = ridge.predict(X_test)\n",
    "print(r2_score(y_test, y_pred_rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb476ffb",
   "metadata": {},
   "source": [
    "### Grid search using Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda79359",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [0.001, 0.01, 0.1, 1, 2, 5]}\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3ee5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for p in params['alpha']:\n",
    "    ridge = Ridge(alpha=p)\n",
    "    results = cross_val_score(ridge, X, y, cv=kfold)\n",
    "    scores.append(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca870ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 5\n",
      "Best score: 0.6003629473268252\n"
     ]
    }
   ],
   "source": [
    "i_max = np.argmax(scores)\n",
    "print(\"Best alpha:\", params['alpha'][i_max])\n",
    "print(\"Best score:\", scores[i_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e77fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 5}\n",
      "0.6003629473268252\n"
     ]
    }
   ],
   "source": [
    "gcv = GridSearchCV(ridge, cv=kfold, param_grid=params)\n",
    "gcv.fit(X, y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292a0e8",
   "metadata": {},
   "source": [
    "### Grid search using Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcabb776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "0.6003715679740543\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.001, 0.01, 0.1, 1, 2, 5]}\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "gcv = GridSearchCV(lasso, cv=kfold, param_grid=params)\n",
    "gcv.fit(X, y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "133d5013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=Lasso(), param_grid={&#x27;alpha&#x27;: [0.001, 1, 2, 5]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=Lasso(), param_grid={&#x27;alpha&#x27;: [0.001, 1, 2, 5]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=Lasso(), param_grid={'alpha': [0.001, 1, 2, 5]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha': [0.001, 1, 2, 5]}\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "gcv_ls = GridSearchCV(lasso, cv=kfold, param_grid=params)\n",
    "gcv_ls.fit(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b917232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "0.6003715679740543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Cement': 0.1198028435517716,\n",
       " 'Blast': 0.10386387483710076,\n",
       " 'Fly': 0.08793328786051845,\n",
       " 'Water': -0.1499360925047414,\n",
       " 'Superplasticizer': 0.29215717900174265,\n",
       " 'Coarse': 0.018082427920204338,\n",
       " 'Fine': 0.020187525533047635,\n",
       " 'Age': 0.11422159725570433}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)\n",
    "best_lasso = gcv_ls.best_estimator_\n",
    "dict(zip(X.columns, best_lasso.coef_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405b555",
   "metadata": {},
   "source": [
    "#### elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b78bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.522e+04, tolerance: 2.258e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+04, tolerance: 2.326e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.482e+04, tolerance: 2.254e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e+04, tolerance: 2.301e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.374e+04, tolerance: 2.344e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.522e+04, tolerance: 2.258e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+04, tolerance: 2.326e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.482e+04, tolerance: 2.254e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e+04, tolerance: 2.301e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.374e+04, tolerance: 2.344e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.527e+04, tolerance: 2.258e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+04, tolerance: 2.326e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.487e+04, tolerance: 2.254e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.338e+04, tolerance: 2.301e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.381e+04, tolerance: 2.344e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.530e+04, tolerance: 2.258e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.324e+04, tolerance: 2.326e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.489e+04, tolerance: 2.254e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.341e+04, tolerance: 2.301e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.385e+04, tolerance: 2.344e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.532e+04, tolerance: 2.258e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.327e+04, tolerance: 2.326e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.491e+04, tolerance: 2.254e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.343e+04, tolerance: 2.301e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.388e+04, tolerance: 2.344e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.547e+04, tolerance: 2.258e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.346e+04, tolerance: 2.326e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.504e+04, tolerance: 2.254e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.359e+04, tolerance: 2.301e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.408e+04, tolerance: 2.344e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.569e+04, tolerance: 2.258e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.371e+04, tolerance: 2.326e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.524e+04, tolerance: 2.254e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.381e+04, tolerance: 2.301e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.435e+04, tolerance: 2.344e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dbda\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.555e+04, tolerance: 2.872e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004792</td>\n",
       "      <td>1.159995e-03</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>3.881715e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 0.001, 'l1_ratio': 0}</td>\n",
       "      <td>0.668250</td>\n",
       "      <td>0.554505</td>\n",
       "      <td>0.657011</td>\n",
       "      <td>0.573937</td>\n",
       "      <td>0.548108</td>\n",
       "      <td>0.600362</td>\n",
       "      <td>0.051671</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.226260e-05</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.840616e-06</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 0.001, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.668249</td>\n",
       "      <td>0.554506</td>\n",
       "      <td>0.657010</td>\n",
       "      <td>0.573937</td>\n",
       "      <td>0.548109</td>\n",
       "      <td>0.600362</td>\n",
       "      <td>0.051671</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002395</td>\n",
       "      <td>4.879249e-04</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>2.740881e-06</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.001, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.668249</td>\n",
       "      <td>0.554506</td>\n",
       "      <td>0.657010</td>\n",
       "      <td>0.573937</td>\n",
       "      <td>0.548109</td>\n",
       "      <td>0.600362</td>\n",
       "      <td>0.051671</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001994</td>\n",
       "      <td>1.997031e-06</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>3.994591e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 0.001, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.668249</td>\n",
       "      <td>0.554506</td>\n",
       "      <td>0.657009</td>\n",
       "      <td>0.573937</td>\n",
       "      <td>0.548109</td>\n",
       "      <td>0.600362</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002198</td>\n",
       "      <td>3.972901e-04</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>3.883368e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0.001, 'l1_ratio': 1}</td>\n",
       "      <td>0.668248</td>\n",
       "      <td>0.554507</td>\n",
       "      <td>0.657009</td>\n",
       "      <td>0.573937</td>\n",
       "      <td>0.548110</td>\n",
       "      <td>0.600362</td>\n",
       "      <td>0.051669</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>4.850147e-04</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.633820e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 0.01, 'l1_ratio': 0}</td>\n",
       "      <td>0.668247</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.657006</td>\n",
       "      <td>0.573936</td>\n",
       "      <td>0.548116</td>\n",
       "      <td>0.600364</td>\n",
       "      <td>0.051666</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>2.381323e-06</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.971818e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 0.01, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.668243</td>\n",
       "      <td>0.554516</td>\n",
       "      <td>0.657001</td>\n",
       "      <td>0.573937</td>\n",
       "      <td>0.548120</td>\n",
       "      <td>0.600363</td>\n",
       "      <td>0.051663</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001996</td>\n",
       "      <td>2.114277e-06</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>2.631692e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.01, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.668243</td>\n",
       "      <td>0.554517</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.573937</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0.600363</td>\n",
       "      <td>0.051662</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001996</td>\n",
       "      <td>1.360449e-06</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>8.529922e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 0.01, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.668236</td>\n",
       "      <td>0.554524</td>\n",
       "      <td>0.656990</td>\n",
       "      <td>0.573940</td>\n",
       "      <td>0.548127</td>\n",
       "      <td>0.600363</td>\n",
       "      <td>0.051655</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001994</td>\n",
       "      <td>1.569758e-05</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>3.997630e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0.01, 'l1_ratio': 1}</td>\n",
       "      <td>0.668232</td>\n",
       "      <td>0.554528</td>\n",
       "      <td>0.656985</td>\n",
       "      <td>0.573941</td>\n",
       "      <td>0.548130</td>\n",
       "      <td>0.600363</td>\n",
       "      <td>0.051652</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004589</td>\n",
       "      <td>8.010477e-04</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>3.746739e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0}</td>\n",
       "      <td>0.667985</td>\n",
       "      <td>0.555161</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>0.573878</td>\n",
       "      <td>0.548909</td>\n",
       "      <td>0.600484</td>\n",
       "      <td>0.051215</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>3.642736e-06</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>4.759781e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.667576</td>\n",
       "      <td>0.555534</td>\n",
       "      <td>0.655957</td>\n",
       "      <td>0.573972</td>\n",
       "      <td>0.549223</td>\n",
       "      <td>0.600453</td>\n",
       "      <td>0.050852</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001797</td>\n",
       "      <td>3.977182e-04</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>2.319410e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.667490</td>\n",
       "      <td>0.555608</td>\n",
       "      <td>0.655848</td>\n",
       "      <td>0.573990</td>\n",
       "      <td>0.549286</td>\n",
       "      <td>0.600444</td>\n",
       "      <td>0.050778</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001996</td>\n",
       "      <td>3.059199e-06</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>3.343305e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.666641</td>\n",
       "      <td>0.556274</td>\n",
       "      <td>0.654807</td>\n",
       "      <td>0.574124</td>\n",
       "      <td>0.549840</td>\n",
       "      <td>0.600337</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001598</td>\n",
       "      <td>4.848595e-04</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>3.653332e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 1}</td>\n",
       "      <td>0.666108</td>\n",
       "      <td>0.556640</td>\n",
       "      <td>0.654184</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0.550140</td>\n",
       "      <td>0.600250</td>\n",
       "      <td>0.049676</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004585</td>\n",
       "      <td>4.888528e-04</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>3.979239e-04</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 1.5, 'l1_ratio': 0}</td>\n",
       "      <td>0.667867</td>\n",
       "      <td>0.555429</td>\n",
       "      <td>0.656243</td>\n",
       "      <td>0.573841</td>\n",
       "      <td>0.549257</td>\n",
       "      <td>0.600527</td>\n",
       "      <td>0.051017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001996</td>\n",
       "      <td>2.757422e-06</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>7.325311e-07</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 1.5, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.667245</td>\n",
       "      <td>0.555964</td>\n",
       "      <td>0.655439</td>\n",
       "      <td>0.573969</td>\n",
       "      <td>0.549705</td>\n",
       "      <td>0.600464</td>\n",
       "      <td>0.050479</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>2.132481e-06</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>2.153700e-06</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1.5, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.667111</td>\n",
       "      <td>0.556071</td>\n",
       "      <td>0.655271</td>\n",
       "      <td>0.573991</td>\n",
       "      <td>0.549794</td>\n",
       "      <td>0.600447</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001802</td>\n",
       "      <td>4.019008e-04</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>1.119339e-05</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 1.5, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.665736</td>\n",
       "      <td>0.557013</td>\n",
       "      <td>0.653635</td>\n",
       "      <td>0.574138</td>\n",
       "      <td>0.550568</td>\n",
       "      <td>0.600218</td>\n",
       "      <td>0.049311</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001796</td>\n",
       "      <td>3.996623e-04</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>3.993045e-04</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1.5, 'l1_ratio': 1}</td>\n",
       "      <td>0.664821</td>\n",
       "      <td>0.557521</td>\n",
       "      <td>0.652617</td>\n",
       "      <td>0.574172</td>\n",
       "      <td>0.550977</td>\n",
       "      <td>0.600022</td>\n",
       "      <td>0.048673</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>4.887536e-04</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.631034e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 2, 'l1_ratio': 0}</td>\n",
       "      <td>0.667757</td>\n",
       "      <td>0.555665</td>\n",
       "      <td>0.656006</td>\n",
       "      <td>0.573802</td>\n",
       "      <td>0.549576</td>\n",
       "      <td>0.600561</td>\n",
       "      <td>0.050834</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>2.934002e-06</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>2.003851e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 2, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.666919</td>\n",
       "      <td>0.556348</td>\n",
       "      <td>0.654928</td>\n",
       "      <td>0.573954</td>\n",
       "      <td>0.550145</td>\n",
       "      <td>0.600459</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001597</td>\n",
       "      <td>4.853344e-04</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>3.848140e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 2, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.666734</td>\n",
       "      <td>0.556483</td>\n",
       "      <td>0.654699</td>\n",
       "      <td>0.573979</td>\n",
       "      <td>0.550257</td>\n",
       "      <td>0.600430</td>\n",
       "      <td>0.049979</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001988</td>\n",
       "      <td>8.568486e-06</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>4.965775e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 2, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.664769</td>\n",
       "      <td>0.557663</td>\n",
       "      <td>0.652420</td>\n",
       "      <td>0.574103</td>\n",
       "      <td>0.551212</td>\n",
       "      <td>0.600033</td>\n",
       "      <td>0.048551</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001988</td>\n",
       "      <td>1.089800e-05</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>1.405368e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'l1_ratio': 1}</td>\n",
       "      <td>0.663393</td>\n",
       "      <td>0.558279</td>\n",
       "      <td>0.650949</td>\n",
       "      <td>0.574078</td>\n",
       "      <td>0.551694</td>\n",
       "      <td>0.599679</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.004192</td>\n",
       "      <td>3.966513e-04</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>3.866333e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0}</td>\n",
       "      <td>0.667248</td>\n",
       "      <td>0.556633</td>\n",
       "      <td>0.654744</td>\n",
       "      <td>0.573526</td>\n",
       "      <td>0.551064</td>\n",
       "      <td>0.600643</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001598</td>\n",
       "      <td>4.866633e-04</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>3.954652e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.665098</td>\n",
       "      <td>0.557965</td>\n",
       "      <td>0.652002</td>\n",
       "      <td>0.573709</td>\n",
       "      <td>0.552137</td>\n",
       "      <td>0.600182</td>\n",
       "      <td>0.048355</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001993</td>\n",
       "      <td>4.371845e-06</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>4.506048e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.664576</td>\n",
       "      <td>0.558214</td>\n",
       "      <td>0.651384</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.552329</td>\n",
       "      <td>0.600043</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>1.482036e-06</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>4.019044e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.661047</td>\n",
       "      <td>0.559964</td>\n",
       "      <td>0.644907</td>\n",
       "      <td>0.572988</td>\n",
       "      <td>0.553517</td>\n",
       "      <td>0.598484</td>\n",
       "      <td>0.045222</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001795</td>\n",
       "      <td>4.021020e-04</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>3.978264e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 1}</td>\n",
       "      <td>0.660989</td>\n",
       "      <td>0.560242</td>\n",
       "      <td>0.643712</td>\n",
       "      <td>0.572545</td>\n",
       "      <td>0.554618</td>\n",
       "      <td>0.598421</td>\n",
       "      <td>0.044748</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.004783</td>\n",
       "      <td>3.992659e-04</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>3.959759e-06</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0}</td>\n",
       "      <td>0.666761</td>\n",
       "      <td>0.557396</td>\n",
       "      <td>0.653057</td>\n",
       "      <td>0.573053</td>\n",
       "      <td>0.552675</td>\n",
       "      <td>0.600589</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.897312e-04</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>3.996461e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.25}</td>\n",
       "      <td>0.662583</td>\n",
       "      <td>0.559288</td>\n",
       "      <td>0.647624</td>\n",
       "      <td>0.573046</td>\n",
       "      <td>0.554078</td>\n",
       "      <td>0.599324</td>\n",
       "      <td>0.046207</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.106495e-07</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.144409e-06</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.662038</td>\n",
       "      <td>0.559581</td>\n",
       "      <td>0.646321</td>\n",
       "      <td>0.572923</td>\n",
       "      <td>0.554258</td>\n",
       "      <td>0.599024</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001395</td>\n",
       "      <td>4.884439e-04</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.662788e-06</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.75}</td>\n",
       "      <td>0.661009</td>\n",
       "      <td>0.561230</td>\n",
       "      <td>0.640257</td>\n",
       "      <td>0.572878</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.598327</td>\n",
       "      <td>0.043545</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001191</td>\n",
       "      <td>3.986512e-04</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>1.239630e-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 1}</td>\n",
       "      <td>0.660892</td>\n",
       "      <td>0.562043</td>\n",
       "      <td>0.637387</td>\n",
       "      <td>0.573372</td>\n",
       "      <td>0.557106</td>\n",
       "      <td>0.598160</td>\n",
       "      <td>0.042611</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.004792  1.159995e-03         0.001193    3.881715e-04       0.001   \n",
       "1        0.002000  1.226260e-05         0.000998    1.840616e-06       0.001   \n",
       "2        0.002395  4.879249e-04         0.000996    2.740881e-06       0.001   \n",
       "3        0.001994  1.997031e-06         0.001199    3.994591e-04       0.001   \n",
       "4        0.002198  3.972901e-04         0.001191    3.883368e-04       0.001   \n",
       "5        0.004388  4.850147e-04         0.000997    1.633820e-06        0.01   \n",
       "6        0.001995  2.381323e-06         0.001197    3.971818e-04        0.01   \n",
       "7        0.001996  2.114277e-06         0.000996    2.631692e-06        0.01   \n",
       "8        0.001996  1.360449e-06         0.000996    8.529922e-07        0.01   \n",
       "9        0.001994  1.569758e-05         0.001196    3.997630e-04        0.01   \n",
       "10       0.004589  8.010477e-04         0.000999    3.746739e-06           1   \n",
       "11       0.001995  3.642736e-06         0.000997    4.759781e-06           1   \n",
       "12       0.001797  3.977182e-04         0.000995    2.319410e-06           1   \n",
       "13       0.001996  3.059199e-06         0.000996    3.343305e-06           1   \n",
       "14       0.001598  4.848595e-04         0.000996    3.653332e-06           1   \n",
       "15       0.004585  4.888528e-04         0.001199    3.979239e-04         1.5   \n",
       "16       0.001996  2.757422e-06         0.000996    7.325311e-07         1.5   \n",
       "17       0.001995  2.132481e-06         0.000996    2.153700e-06         1.5   \n",
       "18       0.001802  4.019008e-04         0.000991    1.119339e-05         1.5   \n",
       "19       0.001796  3.996623e-04         0.001196    3.993045e-04         1.5   \n",
       "20       0.004588  4.887536e-04         0.000997    1.631034e-06           2   \n",
       "21       0.001999  2.934002e-06         0.000995    2.003851e-06           2   \n",
       "22       0.001597  4.853344e-04         0.001195    3.848140e-04           2   \n",
       "23       0.001988  8.568486e-06         0.001402    4.965775e-04           2   \n",
       "24       0.001988  1.089800e-05         0.001005    1.405368e-05           2   \n",
       "25       0.004192  3.966513e-04         0.001193    3.866333e-04           5   \n",
       "26       0.001598  4.866633e-04         0.001195    3.954652e-04           5   \n",
       "27       0.001993  4.371845e-06         0.000999    4.506048e-06           5   \n",
       "28       0.000999  1.482036e-06         0.001196    4.019044e-04           5   \n",
       "29       0.001795  4.021020e-04         0.001196    3.978264e-04           5   \n",
       "30       0.004783  3.992659e-04         0.001002    3.959759e-06          10   \n",
       "31       0.001596  4.897312e-04         0.001195    3.996461e-04          10   \n",
       "32       0.001995  6.106495e-07         0.000997    1.144409e-06          10   \n",
       "33       0.001395  4.884439e-04         0.000998    1.662788e-06          10   \n",
       "34       0.001191  3.986512e-04         0.001002    1.239630e-05          10   \n",
       "\n",
       "   param_l1_ratio                              params  split0_test_score  \\\n",
       "0               0     {'alpha': 0.001, 'l1_ratio': 0}           0.668250   \n",
       "1            0.25  {'alpha': 0.001, 'l1_ratio': 0.25}           0.668249   \n",
       "2             0.3   {'alpha': 0.001, 'l1_ratio': 0.3}           0.668249   \n",
       "3            0.75  {'alpha': 0.001, 'l1_ratio': 0.75}           0.668249   \n",
       "4               1     {'alpha': 0.001, 'l1_ratio': 1}           0.668248   \n",
       "5               0      {'alpha': 0.01, 'l1_ratio': 0}           0.668247   \n",
       "6            0.25   {'alpha': 0.01, 'l1_ratio': 0.25}           0.668243   \n",
       "7             0.3    {'alpha': 0.01, 'l1_ratio': 0.3}           0.668243   \n",
       "8            0.75   {'alpha': 0.01, 'l1_ratio': 0.75}           0.668236   \n",
       "9               1      {'alpha': 0.01, 'l1_ratio': 1}           0.668232   \n",
       "10              0         {'alpha': 1, 'l1_ratio': 0}           0.667985   \n",
       "11           0.25      {'alpha': 1, 'l1_ratio': 0.25}           0.667576   \n",
       "12            0.3       {'alpha': 1, 'l1_ratio': 0.3}           0.667490   \n",
       "13           0.75      {'alpha': 1, 'l1_ratio': 0.75}           0.666641   \n",
       "14              1         {'alpha': 1, 'l1_ratio': 1}           0.666108   \n",
       "15              0       {'alpha': 1.5, 'l1_ratio': 0}           0.667867   \n",
       "16           0.25    {'alpha': 1.5, 'l1_ratio': 0.25}           0.667245   \n",
       "17            0.3     {'alpha': 1.5, 'l1_ratio': 0.3}           0.667111   \n",
       "18           0.75    {'alpha': 1.5, 'l1_ratio': 0.75}           0.665736   \n",
       "19              1       {'alpha': 1.5, 'l1_ratio': 1}           0.664821   \n",
       "20              0         {'alpha': 2, 'l1_ratio': 0}           0.667757   \n",
       "21           0.25      {'alpha': 2, 'l1_ratio': 0.25}           0.666919   \n",
       "22            0.3       {'alpha': 2, 'l1_ratio': 0.3}           0.666734   \n",
       "23           0.75      {'alpha': 2, 'l1_ratio': 0.75}           0.664769   \n",
       "24              1         {'alpha': 2, 'l1_ratio': 1}           0.663393   \n",
       "25              0         {'alpha': 5, 'l1_ratio': 0}           0.667248   \n",
       "26           0.25      {'alpha': 5, 'l1_ratio': 0.25}           0.665098   \n",
       "27            0.3       {'alpha': 5, 'l1_ratio': 0.3}           0.664576   \n",
       "28           0.75      {'alpha': 5, 'l1_ratio': 0.75}           0.661047   \n",
       "29              1         {'alpha': 5, 'l1_ratio': 1}           0.660989   \n",
       "30              0        {'alpha': 10, 'l1_ratio': 0}           0.666761   \n",
       "31           0.25     {'alpha': 10, 'l1_ratio': 0.25}           0.662583   \n",
       "32            0.3      {'alpha': 10, 'l1_ratio': 0.3}           0.662038   \n",
       "33           0.75     {'alpha': 10, 'l1_ratio': 0.75}           0.661009   \n",
       "34              1        {'alpha': 10, 'l1_ratio': 1}           0.660892   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.554505           0.657011           0.573937   \n",
       "1            0.554506           0.657010           0.573937   \n",
       "2            0.554506           0.657010           0.573937   \n",
       "3            0.554506           0.657009           0.573937   \n",
       "4            0.554507           0.657009           0.573937   \n",
       "5            0.554512           0.657006           0.573936   \n",
       "6            0.554516           0.657001           0.573937   \n",
       "7            0.554517           0.657000           0.573937   \n",
       "8            0.554524           0.656990           0.573940   \n",
       "9            0.554528           0.656985           0.573941   \n",
       "10           0.555161           0.656489           0.573878   \n",
       "11           0.555534           0.655957           0.573972   \n",
       "12           0.555608           0.655848           0.573990   \n",
       "13           0.556274           0.654807           0.574124   \n",
       "14           0.556640           0.654184           0.574180   \n",
       "15           0.555429           0.656243           0.573841   \n",
       "16           0.555964           0.655439           0.573969   \n",
       "17           0.556071           0.655271           0.573991   \n",
       "18           0.557013           0.653635           0.574138   \n",
       "19           0.557521           0.652617           0.574172   \n",
       "20           0.555665           0.656006           0.573802   \n",
       "21           0.556348           0.654928           0.573954   \n",
       "22           0.556483           0.654699           0.573979   \n",
       "23           0.557663           0.652420           0.574103   \n",
       "24           0.558279           0.650949           0.574078   \n",
       "25           0.556633           0.654744           0.573526   \n",
       "26           0.557965           0.652002           0.573709   \n",
       "27           0.558214           0.651384           0.573711   \n",
       "28           0.559964           0.644907           0.572988   \n",
       "29           0.560242           0.643712           0.572545   \n",
       "30           0.557396           0.653057           0.573053   \n",
       "31           0.559288           0.647624           0.573046   \n",
       "32           0.559581           0.646321           0.572923   \n",
       "33           0.561230           0.640257           0.572878   \n",
       "34           0.562043           0.637387           0.573372   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.548108         0.600362        0.051671               17  \n",
       "1            0.548109         0.600362        0.051671               18  \n",
       "2            0.548109         0.600362        0.051671               19  \n",
       "3            0.548109         0.600362        0.051670               20  \n",
       "4            0.548110         0.600362        0.051669               21  \n",
       "5            0.548116         0.600364        0.051666               12  \n",
       "6            0.548120         0.600363        0.051663               13  \n",
       "7            0.548121         0.600363        0.051662               14  \n",
       "8            0.548127         0.600363        0.051655               15  \n",
       "9            0.548130         0.600363        0.051652               16  \n",
       "10           0.548909         0.600484        0.051215                5  \n",
       "11           0.549223         0.600453        0.050852                8  \n",
       "12           0.549286         0.600444        0.050778               10  \n",
       "13           0.549840         0.600337        0.050084               22  \n",
       "14           0.550140         0.600250        0.049676               23  \n",
       "15           0.549257         0.600527        0.051017                4  \n",
       "16           0.549705         0.600464        0.050479                6  \n",
       "17           0.549794         0.600447        0.050368                9  \n",
       "18           0.550568         0.600218        0.049311               24  \n",
       "19           0.550977         0.600022        0.048673               28  \n",
       "20           0.549576         0.600561        0.050834                3  \n",
       "21           0.550145         0.600459        0.050127                7  \n",
       "22           0.550257         0.600430        0.049979               11  \n",
       "23           0.551212         0.600033        0.048551               27  \n",
       "24           0.551694         0.599679        0.047665               29  \n",
       "25           0.551064         0.600643        0.049987                1  \n",
       "26           0.552137         0.600182        0.048355               25  \n",
       "27           0.552329         0.600043        0.048000               26  \n",
       "28           0.553517         0.598484        0.045222               32  \n",
       "29           0.554618         0.598421        0.044748               33  \n",
       "30           0.552675         0.600589        0.049094                2  \n",
       "31           0.554078         0.599324        0.046207               30  \n",
       "32           0.554258         0.599024        0.045714               31  \n",
       "33           0.556259         0.598327        0.043545               34  \n",
       "34           0.557106         0.598160        0.042611               35  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic = ElasticNet()\n",
    "elastic.fit(X_train, y_train)\n",
    "params = {'alpha': [0.001, 0.01, 1, 1.5, 2, 5, 10],\n",
    "         'l1_ratio': [0, 0.25, 0.3, 0.75, 1 ]}\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "params\n",
    "gcv = GridSearchCV(elastic, cv=kfold, param_grid=params)\n",
    "gcv.fit(X,y)\n",
    "pd.DataFrame(gcv.cv_results_)\n",
    "#gcv.cv_results_ gives o/p as dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bc9583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 5, 'l1_ratio': 0}\n",
      "0.600643179394704\n"
     ]
    }
   ],
   "source": [
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc75997e",
   "metadata": {},
   "source": [
    "#### Best estimatior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35746811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cement': 0.1198028435517716,\n",
       " 'Blast': 0.10386387483710076,\n",
       " 'Fly': 0.08793328786051845,\n",
       " 'Water': -0.1499360925047414,\n",
       " 'Superplasticizer': 0.29215717900174265,\n",
       " 'Coarse': 0.018082427920204338,\n",
       " 'Fine': 0.020187525533047635,\n",
       " 'Age': 0.11422159725570433}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_el = gcv_ls.best_estimator_\n",
    "dict(zip(X.columns, best_el.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "059045c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-23.321076605123253,\n",
       " array([ 0.11980284,  0.10386387,  0.08793329, -0.14993609,  0.29215718,\n",
       "         0.01808243,  0.02018753,  0.1142216 ]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_el.intercept_, best_el.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee003ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.73746243, 31.79008383, 19.49411398, 46.85099828, 58.04230926,\n",
       "       16.09500148, 50.35397155, 80.31070596, 31.13524312, 41.56861521,\n",
       "       43.44398337, 60.77099675, 52.37229437, 15.38766485])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(r\"F:\\PML\\Cases\\Concrete_Strength\\testConcrete.csv\")\n",
    "best_es = gcv_ls.best_estimator_\n",
    "best_es.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
